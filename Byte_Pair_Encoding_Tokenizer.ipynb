{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTlAvhpgVr+GkbsOv9UEV7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import collections"
      ],
      "metadata": {
        "id": "t0Acqe2Mm_Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-Q-vURKjedQr"
      },
      "outputs": [],
      "source": [
        "# corpus for training\n",
        "\n",
        "corpus = [\n",
        "    \"The sun set behind the mountains, casting a golden glow across the landscape.\",\n",
        "\n",
        "\"She walked through the quiet forest, her footsteps muffled by the soft blanket of fallen leaves.\",\n",
        "\n",
        "\"The aroma of freshly brewed coffee filled the air as he sat down at the kitchen table.\",\n",
        "\n",
        "\"In the distance, the sound of a river flowing peacefully echoed through the valley.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoXDcNLffgTk",
        "outputId": "03f873db-79c1-47ec-b09a-f33ffbdadf9d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The sun set behind the mountains, casting a golden glow across the landscape.',\n",
              " 'She walked through the quiet forest, her footsteps muffled by the soft blanket of fallen leaves.',\n",
              " 'The aroma of freshly brewed coffee filled the air as he sat down at the kitchen table.',\n",
              " 'In the distance, the sound of a river flowing peacefully echoed through the valley.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize vocabulary with unique characters\n",
        "unique_chars = set()\n",
        "for sentence in corpus:\n",
        "    for char in sentence:\n",
        "        unique_chars.add(char)\n",
        "\n",
        "vocab = list(unique_chars)\n",
        "vocab.sort()\n",
        "\n",
        "# add special token at end of word token\n",
        "end_of_word = '<|endofword|>'\n",
        "vocab.append(end_of_word)"
      ],
      "metadata": {
        "id": "A-RVz7eFfnRJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"vocabulary:\" , vocab)\n",
        "print(\"length of vocabulary:\" , len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VObrcpvsg2Iy",
        "outputId": "02e15a74-3d03-4630-ba11-27fb0b937d4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary: [' ', ',', '.', 'I', 'S', 'T', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'y', '<|endofword|>']\n",
            "length of vocabulary: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pre tokenize the corpus(split into word->then characters)\n",
        "\n",
        "word_split = {}\n",
        "for sentence in corpus:\n",
        "  words = sentence.split(' ')\n",
        "  print(\"words:------------\",words)\n",
        "  for word in words:\n",
        "    if word:\n",
        "      char_list = list(word) + [end_of_word]\n",
        "      print(\"char_list:---------\",char_list)\n",
        "      word_tuple = tuple(char_list)\n",
        "\n",
        "      if word_tuple not in word_split:\n",
        "        word_split[word_tuple] = 0\n",
        "      word_split[word_tuple] += 1 #this count freq of each initial word split\n",
        "\n",
        "\n",
        "print(\"word_split:------------\",word_split)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DE8cNvubhM-c",
        "outputId": "950bfe1a-e069-4194-8854-de9dbe2019d9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words:------------ ['The', 'sun', 'set', 'behind', 'the', 'mountains,', 'casting', 'a', 'golden', 'glow', 'across', 'the', 'landscape.']\n",
            "char_list:--------- ['T', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['s', 'u', 'n', '<|endofword|>']\n",
            "char_list:--------- ['s', 'e', 't', '<|endofword|>']\n",
            "char_list:--------- ['b', 'e', 'h', 'i', 'n', 'd', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['m', 'o', 'u', 'n', 't', 'a', 'i', 'n', 's', ',', '<|endofword|>']\n",
            "char_list:--------- ['c', 'a', 's', 't', 'i', 'n', 'g', '<|endofword|>']\n",
            "char_list:--------- ['a', '<|endofword|>']\n",
            "char_list:--------- ['g', 'o', 'l', 'd', 'e', 'n', '<|endofword|>']\n",
            "char_list:--------- ['g', 'l', 'o', 'w', '<|endofword|>']\n",
            "char_list:--------- ['a', 'c', 'r', 'o', 's', 's', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['l', 'a', 'n', 'd', 's', 'c', 'a', 'p', 'e', '.', '<|endofword|>']\n",
            "words:------------ ['She', 'walked', 'through', 'the', 'quiet', 'forest,', 'her', 'footsteps', 'muffled', 'by', 'the', 'soft', 'blanket', 'of', 'fallen', 'leaves.']\n",
            "char_list:--------- ['S', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['w', 'a', 'l', 'k', 'e', 'd', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'r', 'o', 'u', 'g', 'h', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['q', 'u', 'i', 'e', 't', '<|endofword|>']\n",
            "char_list:--------- ['f', 'o', 'r', 'e', 's', 't', ',', '<|endofword|>']\n",
            "char_list:--------- ['h', 'e', 'r', '<|endofword|>']\n",
            "char_list:--------- ['f', 'o', 'o', 't', 's', 't', 'e', 'p', 's', '<|endofword|>']\n",
            "char_list:--------- ['m', 'u', 'f', 'f', 'l', 'e', 'd', '<|endofword|>']\n",
            "char_list:--------- ['b', 'y', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['s', 'o', 'f', 't', '<|endofword|>']\n",
            "char_list:--------- ['b', 'l', 'a', 'n', 'k', 'e', 't', '<|endofword|>']\n",
            "char_list:--------- ['o', 'f', '<|endofword|>']\n",
            "char_list:--------- ['f', 'a', 'l', 'l', 'e', 'n', '<|endofword|>']\n",
            "char_list:--------- ['l', 'e', 'a', 'v', 'e', 's', '.', '<|endofword|>']\n",
            "words:------------ ['The', 'aroma', 'of', 'freshly', 'brewed', 'coffee', 'filled', 'the', 'air', 'as', 'he', 'sat', 'down', 'at', 'the', 'kitchen', 'table.']\n",
            "char_list:--------- ['T', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['a', 'r', 'o', 'm', 'a', '<|endofword|>']\n",
            "char_list:--------- ['o', 'f', '<|endofword|>']\n",
            "char_list:--------- ['f', 'r', 'e', 's', 'h', 'l', 'y', '<|endofword|>']\n",
            "char_list:--------- ['b', 'r', 'e', 'w', 'e', 'd', '<|endofword|>']\n",
            "char_list:--------- ['c', 'o', 'f', 'f', 'e', 'e', '<|endofword|>']\n",
            "char_list:--------- ['f', 'i', 'l', 'l', 'e', 'd', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['a', 'i', 'r', '<|endofword|>']\n",
            "char_list:--------- ['a', 's', '<|endofword|>']\n",
            "char_list:--------- ['h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['s', 'a', 't', '<|endofword|>']\n",
            "char_list:--------- ['d', 'o', 'w', 'n', '<|endofword|>']\n",
            "char_list:--------- ['a', 't', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['k', 'i', 't', 'c', 'h', 'e', 'n', '<|endofword|>']\n",
            "char_list:--------- ['t', 'a', 'b', 'l', 'e', '.', '<|endofword|>']\n",
            "words:------------ ['In', 'the', 'distance,', 'the', 'sound', 'of', 'a', 'river', 'flowing', 'peacefully', 'echoed', 'through', 'the', 'valley.']\n",
            "char_list:--------- ['I', 'n', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['d', 'i', 's', 't', 'a', 'n', 'c', 'e', ',', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['s', 'o', 'u', 'n', 'd', '<|endofword|>']\n",
            "char_list:--------- ['o', 'f', '<|endofword|>']\n",
            "char_list:--------- ['a', '<|endofword|>']\n",
            "char_list:--------- ['r', 'i', 'v', 'e', 'r', '<|endofword|>']\n",
            "char_list:--------- ['f', 'l', 'o', 'w', 'i', 'n', 'g', '<|endofword|>']\n",
            "char_list:--------- ['p', 'e', 'a', 'c', 'e', 'f', 'u', 'l', 'l', 'y', '<|endofword|>']\n",
            "char_list:--------- ['e', 'c', 'h', 'o', 'e', 'd', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'r', 'o', 'u', 'g', 'h', '<|endofword|>']\n",
            "char_list:--------- ['t', 'h', 'e', '<|endofword|>']\n",
            "char_list:--------- ['v', 'a', 'l', 'l', 'e', 'y', '.', '<|endofword|>']\n",
            "word_split:------------ {('T', 'h', 'e', '<|endofword|>'): 2, ('s', 'u', 'n', '<|endofword|>'): 1, ('s', 'e', 't', '<|endofword|>'): 1, ('b', 'e', 'h', 'i', 'n', 'd', '<|endofword|>'): 1, ('t', 'h', 'e', '<|endofword|>'): 9, ('m', 'o', 'u', 'n', 't', 'a', 'i', 'n', 's', ',', '<|endofword|>'): 1, ('c', 'a', 's', 't', 'i', 'n', 'g', '<|endofword|>'): 1, ('a', '<|endofword|>'): 2, ('g', 'o', 'l', 'd', 'e', 'n', '<|endofword|>'): 1, ('g', 'l', 'o', 'w', '<|endofword|>'): 1, ('a', 'c', 'r', 'o', 's', 's', '<|endofword|>'): 1, ('l', 'a', 'n', 'd', 's', 'c', 'a', 'p', 'e', '.', '<|endofword|>'): 1, ('S', 'h', 'e', '<|endofword|>'): 1, ('w', 'a', 'l', 'k', 'e', 'd', '<|endofword|>'): 1, ('t', 'h', 'r', 'o', 'u', 'g', 'h', '<|endofword|>'): 2, ('q', 'u', 'i', 'e', 't', '<|endofword|>'): 1, ('f', 'o', 'r', 'e', 's', 't', ',', '<|endofword|>'): 1, ('h', 'e', 'r', '<|endofword|>'): 1, ('f', 'o', 'o', 't', 's', 't', 'e', 'p', 's', '<|endofword|>'): 1, ('m', 'u', 'f', 'f', 'l', 'e', 'd', '<|endofword|>'): 1, ('b', 'y', '<|endofword|>'): 1, ('s', 'o', 'f', 't', '<|endofword|>'): 1, ('b', 'l', 'a', 'n', 'k', 'e', 't', '<|endofword|>'): 1, ('o', 'f', '<|endofword|>'): 3, ('f', 'a', 'l', 'l', 'e', 'n', '<|endofword|>'): 1, ('l', 'e', 'a', 'v', 'e', 's', '.', '<|endofword|>'): 1, ('a', 'r', 'o', 'm', 'a', '<|endofword|>'): 1, ('f', 'r', 'e', 's', 'h', 'l', 'y', '<|endofword|>'): 1, ('b', 'r', 'e', 'w', 'e', 'd', '<|endofword|>'): 1, ('c', 'o', 'f', 'f', 'e', 'e', '<|endofword|>'): 1, ('f', 'i', 'l', 'l', 'e', 'd', '<|endofword|>'): 1, ('a', 'i', 'r', '<|endofword|>'): 1, ('a', 's', '<|endofword|>'): 1, ('h', 'e', '<|endofword|>'): 1, ('s', 'a', 't', '<|endofword|>'): 1, ('d', 'o', 'w', 'n', '<|endofword|>'): 1, ('a', 't', '<|endofword|>'): 1, ('k', 'i', 't', 'c', 'h', 'e', 'n', '<|endofword|>'): 1, ('t', 'a', 'b', 'l', 'e', '.', '<|endofword|>'): 1, ('I', 'n', '<|endofword|>'): 1, ('d', 'i', 's', 't', 'a', 'n', 'c', 'e', ',', '<|endofword|>'): 1, ('s', 'o', 'u', 'n', 'd', '<|endofword|>'): 1, ('r', 'i', 'v', 'e', 'r', '<|endofword|>'): 1, ('f', 'l', 'o', 'w', 'i', 'n', 'g', '<|endofword|>'): 1, ('p', 'e', 'a', 'c', 'e', 'f', 'u', 'l', 'l', 'y', '<|endofword|>'): 1, ('e', 'c', 'h', 'o', 'e', 'd', '<|endofword|>'): 1, ('v', 'a', 'l', 'l', 'e', 'y', '.', '<|endofword|>'): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Function: `get_pair_stats`\n",
        "\n",
        "```This function takes the current word splits (represented as a dictionary where keys are tuples of symbols/characters forming a word and values are their frequencies) and calculates the frequency of each adjacent pair of symbols across the entire corpus.```\n",
        "\n",
        "```\n",
        "**Input Example (`splits`):**\n",
        "\n",
        " {('T', 'h', 'i', 's', '<|endofword|>'): 2, ('i', 's', '<|endofword|>'): 2, ...}\n",
        "\n",
        "**Output Example (`pair_counts`):**\n",
        "\n",
        "{('i', 's'): 4, ('s', '<|endofword|>'): 4, ('T', 'h'): 2, ...} ```\n"
      ],
      "metadata": {
        "id": "iO8qUt-Ll53H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pair_stats(splits):\n",
        "  pair_counts = collections.defaultdict(int)\n",
        "  for word_tuple, freq in splits.items():\n",
        "      symbols = list(word_tuple)\n",
        "      for i in range(len(symbols)-1):\n",
        "        pair = (symbols[i],symbols[i+1])\n",
        "        pair_counts[pair] += freq\n",
        "  return pair_counts\n"
      ],
      "metadata": {
        "id": "acTndRRym5zf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper Function: `merge_pair`\n",
        "\n",
        "\n",
        "This function takes a specific pair (`pair_to_merge`) that we want to combine and the current `splits`. It iterates through all the word representations in `splits`, replaces occurrences of the `pair_to_merge` with a new single token (concatenation of the pair), and returns the updated `splits`.\n",
        "\n",
        "```\n",
        "**Input Example:**\n",
        "`pair_to_merge`: `('i', 's')`\n",
        "`splits`: `{('T', 'h', 'i', 's', '<|endofword|>'): 2, ('i', 's', '<|endofword|>'): 2, ...}`\n",
        "\n",
        "**Output Example (`new_splits`):**\n",
        "`{('T', 'h', 'is', '<|endofword|>'): 2, ('is', '<|endofword|>'): 2, ...}` (assuming 'is' is the merged token)\n",
        "```"
      ],
      "metadata": {
        "id": "MOtu5nvio1Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_pairs(pair_to_merge, splits):\n",
        "  new_splits = {}\n",
        "  (first, second) = pair_to_merge\n",
        "  merged_token = first + second\n",
        "  for word_tuple , freq in splits.items():\n",
        "    symbols = list(word_tuple)\n",
        "    new_symbols = []\n",
        "    i = 0\n",
        "    while i < len(symbols):\n",
        "      if i < len(symbols) - 1 and symbols[i] == first and symbols[i+1] == second:\n",
        "        new_symbols.append(merged_token)\n",
        "        i += 2\n",
        "      else:\n",
        "        new_symbols.append(symbols[i])\n",
        "        i += 1\n",
        "\n",
        "    new_splits[tuple(new_symbols)] = freq\n",
        "  return new_splits"
      ],
      "metadata": {
        "id": "M53-KxQXm-H3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hh2XkiA_q2a4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}